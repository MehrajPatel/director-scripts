#
# Copyright (c) 2017-2019 Cloudera, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
#
# Sample Cloudera Altus Director configuration file based on the Cloudera Azure reference architecture:
# http://www.cloudera.com/documentation/other/reference-architecture/PDF/cloudera_ref_arch_azure.pdf
#
# Highly Available cluster with 3 master nodes and 5 worker nodes, with Kerberos enabled
#


#
# Cluster name
#
# If environmentName and deploymentName are not defined they will get the value of 'name'.
# Must be unique.
#

name: C6-Kerberos-Azure

#
# Environment name
#

environmentName: Azure-Kerberos-HA

#
# Deployment name
# Used to name the Cloudera Manager instance in Cloudera Altus Director.
# Must be unique.
#

deploymentName: Cloudera-Manager-on-Azure


#
# Cloud provider configuration (credentials, region or zone, and more)
#

provider {
    type: azure

    #
    # ID of Azure region to use. NOTE: region must support Premium Storage
    # See: https://azure.microsoft.com/en-us/global-infrastructure/regions/
    #

    region: "region_REPLACE_ME"

    #
    # Azure Cloud Environment to use. Valid values are:
    #   - azure
    #   - azure-us-government
    #   - azure-germany
    #

    azureCloudEnvironment: "azureCloudEnvironment_REPLACE_ME"

    #
    # Azure Active Directory Subscription ID.
    #

    subscriptionId: "subscriptionId_REPLACE_ME"

    #
    # Tenant ID (from AAD)
    #

    tenantId: "tenantId_REPLACE_ME"

    #
    # Azure Active Directory Application Client ID.
    #

    clientId: "clientId_REPLACE_ME"

    #
    # Client Secret
    #

    clientSecret: "clientSecret_REPLACE_ME"
}


#
# SSH credentials to use to connect to the machines
#

ssh {
    username: "username_REPLACE_ME"
    privateKey: privateKey_REPLACE_ME # with an absolute path to .pem file, ${HOME} may be used
}

#
# Instance templates
#
# See azure.reference.conf for a breakdown of instance template fields.
#

instances {

    # fields that are common to all nodes
    base {
        type: STANDARD_D32S_V3
        image: cloudera-centos-72-latest
        automatic: false
        networkSecurityGroupResourceGroup: "networkSecurityGroupResourceGroup_REPLACE_ME"
        networkSecurityGroup: "networkSecurityGroup_REPLACE_ME"
        virtualNetworkResourceGroup: "virtualNetworkResourceGroup_REPLACE_ME"
        virtualNetwork: "virtualNetwork_REPLACE_ME"
        subnetName: "subnetName_REPLACE_ME"
        hostFqdnSuffix: "hostFqdnSuffix_REPLACE_ME"
        tags {
            owner: ${?USER}
        }
        bootstrapScripts: [ ${?bootstrap-script.os-generic} ]
    }

    # fields for master nodes
    master: ${instances.base} {
        computeResourceGroup: "master_computeResourceGroup_REPLACE_ME"
        availabilitySet: "master_availabilitySet_REPLACE_ME"
        instanceNamePrefix: "master_instanceNamePrefix_REPLACE_ME"
        storageAccountType: "Premium_LRS"
        dataDiskSize: 512
        managedDisks: Yes
        useCustomManagedImage: No
        publicIP: No
    }

    # fields for master-1 nodes
    master-1: ${instances.master} {
        dataDiskCount: 4
    }

    # fields for master-2 nodes
    master-2: ${instances.master} {
        dataDiskCount: 3
    }

    # fields for worker nodes
    worker: ${instances.base} {
        computeResourceGroup: "worker_computeResourceGroup_REPLACE_ME"
        availabilitySet: "worker_availabilitySet_REPLACE_ME"
        instanceNamePrefix: "worker_instanceNamePrefix_REPLACE_ME"
        storageAccountType: "Standard_LRS"
        dataDiskCount: 11
        dataDiskSize: 1024
        managedDisks: Yes
        publicIP: No
    }

    # fields for edge nodes
    edge: ${instances.base} {
        computeResourceGroup: "edge_computeResourceGroup_REPLACE_ME"
        availabilitySet: "edge_availabilitySet_REPLACE_ME"
        instanceNamePrefix: "edge_instanceNamePrefix_REPLACE_ME"
        storageAccountType: "Standard_LRS"
        dataDiskCount: 1
        dataDiskSize: 512
        managedDisks: Yes
        # Change this to Yes to allow accessing edge/CM nodes via public IP
        publicIP: No
    }
}

include "azure-os-generic-bootstrap.conf"

#
# Optional external database server configuration.
#
# Cloudera Altus Director can create databases on existing database servers,
# including MySQL servers running in Azure MySQL.
#
# To properly setup a database see:
# https://www.cloudera.com/documentation/director/latest/topics/director_get_started_azure_set_up_msql_postgres.html
#
# See azure.reference.conf for a breakdown of database server template fields.
#
#

databaseServers {

  existingmysql1 {
    type: mysql
    host: mysql_host_REPLACE_ME.mysql.database.azure.com
    port: 3306
    user: "root@mysql_host_REPLACE_ME"
    password: rootpassword
  }

}

#
# Configuration for Cloudera Manager. Cloudera Altus Director can use an existing Cloudera
# Manager installation, or bootstrap everything from scratch for a new cluster.
#

cloudera-manager {

    instance: ${instances.edge} {

        #
        # Additional tags for the Cloudera Manager instance
        #

        tags {
            application: "Cloudera Manager 6"
        }
    }

    #
    # Activate 60-Day Cloudera Enterprise Trial
    #

    enableEnterpriseTrial: true

    #
    # Install the unlimited strength JCE policy files for higher levels of encryption.
    # Prior to setting this to true, confirm that you understand the legal ramifications
    # of using unlimited JCE policy files in your country.
    #

    unlimitedJce: true

    #
    # Kerberos Credentials
    #

    #
    # An administrative Kerberos account capable of creating principals on the KDC that
    # Cloudera Manager will be using. This will typically be in the format:
    #    Principal@YOUR.KDC.REALM
    #

    krbAdminUsername: "krbAdminUsername_REPLACE_ME"


    #
    # The password for the administrative Kerberos account.
    #

    krbAdminPassword: "krbAdminPassword_REPLACE_ME"


    #
    # Optional database configuration
    #
    # There are three mutually exclusive options for database usage in Cloudera Altus Director.
    # 1. With no configuration, databases in the Cloudera Manager embedded PostgreSQL database
    #    server will be used. This option is NOT supported for production use.
    # 2. Alternatively, existing external databases can be used.
    # 3. Finally, databases can be created on the fly on existing external database servers.
    #
    # Note that using an external database here necessitates using an external database
    # for the cluster services. This reference configuration is using Option 3.
    #

    #
    # (Option 2) Optional configuration for existing external databases
    #

    # databases {
    #     CLOUDERA_MANAGER {
    #         type: postgresql
    #
    #         host: db.example.com
    #         port: 123
    #
    #         user: admin
    #         password: 1231ed
    #
    #         name: scm
    #     }
    #
    #     ACTIVITYMONITOR { ... }
    #
    #     REPORTSMANAGER { ... }
    #
    #     NAVIGATOR { ... }
    #
    #     NAVIGATORMETASERVER { ... }
    # }

    #
    # (Option 3) Optional configuration for creating external databases on the fly
    #
    # When a database is created on the fly, Altus Director generates a random database name using the specified
    # database name prefix, a random username based on the specified username prefix, and a random password. The
    # password is stored by Altus Director and made available to the service that uses the database. If multiple
    # services reference the same external database server, Altus Director will create a database for each.
    #
    # MySQL limits usernames to sixteen characters. Therefore, limit usernamePrefix values for databases on MySQL to
    # seven characters; the remaining nine characters are used by the randomized suffix generated by Director.
    #
    # Note that the databaseServerName must correspond to an external database server named above.
    #

    databaseTemplates {
        CLOUDERA_MANAGER {
            name: scmt
            databaseServerName: existingmysql1
            databaseNamePrefix: scm
            usernamePrefix: scmu
        }

        ACTIVITYMONITOR {
            name: amont
            databaseServerName: existingmysql1
            databaseNamePrefix: amon
            usernamePrefix: amonu
        }

        REPORTSMANAGER {
            name: rmant
            databaseServerName: existingmysql1
            databaseNamePrefix: rman
            usernamePrefix: rmanu
        }

        NAVIGATOR {
            name: navt
            databaseServerName: existingmysql1
            databaseNamePrefix: nav
            usernamePrefix: navu
        }

        NAVIGATORMETASERVER {
            name: navmst
            databaseServerName: existingmysql1
            databaseNamePrefix: navms
            usernamePrefix: navmsu
        }
    }

    #
    # Configuration for Cloudera Manager and its management services
    #
    # Configuration properties for CLOUDERA_MANAGER are documented at
    # https://www.cloudera.com/documentation/enterprise/6/properties/6.3/topics/cm_props_cmserver.html
    #
    # Configuration properties for the Cloudera Management services are documented at
    # https://www.cloudera.com/documentation/enterprise/6/properties/6.3/topics/cm_props_mgmtservice.html
    #
    # Configuration properties for Hosts are documented at
    # https://www.cloudera.com/documentation/enterprise/6/properties/6.3/topics/cm_props_host.html
    #

    configs {

        #
        # CLOUDERA_MANAGER corresponds to the Cloudera Manager Server configuration options
        #

        CLOUDERA_MANAGER {
            # enable_api_debug: true
            custom_banner_html: "Managed by Cloudera Altus Director"

            #
            # Kerberos Configurations
            #

            #
            # The type of KDC Cloudera Manager will be using. Valid values are "MIT KDC"
            # and "Active Directory"
            #

            KDC_TYPE: "MIT KDC"

            #
            # The KDC host name or IP address.
            #

            KDC_HOST: "KDC_HOST_REPLACE_ME"

            #
            # The security realm that your KDC uses. This will be of the format of a fully
            # qualified domain name:
            #    YOUR.KDC.REALM
            #

            SECURITY_REALM: "SECURITY_REALM_REPLACE_ME"

            #
            # The Active Directory KDC domain. Only applicable to Active Directory KDCs. This
            # will be in the format of an X.500 Directory Specification:
            #    DC=domain,DC=example,DC=com
            #

            # AD_KDC_DOMAIN: "AD_KDC_DOMAIN_REPLACE_ME"

            #
            # Allow Cloudera Manager to deploy Kerberos configurations to hosts. This should
            # be set to true unless you have an alternate mechanism to generate or retrieve the
            # Kerberos configuration on your Cloudera Manager node instances.
            #

            KRB_MANAGE_KRB5_CONF: true

            #
            # The encryption types your KDC supports. Some of those listed below will require the
            # unlimited strength JCE policy files.
            #

            KRB_ENC_TYPES: "aes256-cts aes128-cts des3-hmac-sha1 arcfour-hmac des-hmac-sha1 des-cbc-md5 des-cbc-crc"

            #
            # There are many more optional Kerberos configuration options available to Cloudera Manager.
            # Please refer to the Kerberos section of Cloudera Enterprise documentation for more details.
            #
        }

        SERVICEMONITOR {
            mgmt_log_dir: /data0/log/cloudera-scm-firehose
            firehose_storage_dir: /data0/lib/cloudera-service-monitor
        }

        ACTIVITYMONITOR {
            mgmt_log_dir: /data0/log/cloudera-scm-firehose
        }

        HOSTMONITOR {
            mgmt_log_dir: /data0/log/cloudera-scm-firehose
            firehose_storage_dir: /data0/lib/cloudera-host-monitor
        }

        REPORTSMANAGER {
            headlamp_scratch_dir: /data0/lib/cloudera-scm-headlamp
            mgmt_log_dir: /data0/log/cloudera-scm-headlamp
        }

        EVENTSERVER {
            mgmt_log_dir: /data0/log/cloudera-scm-eventserver
            eventserver_index_dir: /data0/lib/cloudera-scm-eventserver
        }

        ALERTPUBLISHER {
            mgmt_log_dir: /data0/log/cloudera-scm-alertpublisher
        }

        NAVIGATOR {
            mgmt_log_dir: /data0/log/cloudera-scm-navigator
        }

        NAVIGATORMETASERVER {
            audit_event_log_dir: /data0/log/cloudera-scm-navigator/audit
            data_dir: /data0/lib/cloudera-scm-navigator
            mgmt_log_dir: /data0/log/cloudera-scm-navigator
        }

    }

}

#
# Cluster description
#

cluster {

    # The table of products and their versions that need to be installed. Each
    # product must have a corresponding parcel in the parcelRepositories
    # configured in this section. The specified version for a product will be
    # used to find a suitable parcel. Specifying a version that is satisfied by
    # more than one parcel among those available will result in a configuration
    # error. Specify more granular versions to avoid conflicts.

    products {
        CDH: 6
    }

    #
    # Optional override of CDH parcel repositories
    #
    # This defaults to the Cloudera Enterprise release corresponding to the
    # Altus Director version.
    #

    # parcelRepositories: ["https://archive.cloudera.com/cdh6/6.3/parcels/"]

    #
    # Services to include in the cluster
    #
    # NOTE: On CM 5.9+ Sentry and Kafka 2.0 can't coexist in the same cluster.
    #       If this is needed, use CM 5.8 repository and parcels, or use Kafka
    #       2.1 or higher.
    #

    services: [
      HDFS,
      YARN,
      ZOOKEEPER,
      HBASE,
      HIVE,
      HUE,
      IMPALA,
      OOZIE,
      SPARK_ON_YARN
    ]

    #
    # Custom service configurations
    #
    # Configuration keys containing special characters (e.g., '.', ':') must be enclosed in double
    # quotes.
    #
    # Configuration properties for CDH roles and services are documented at
    # https://www.cloudera.com/documentation/enterprise/6/properties/6.3/topics/cm_props_cdh620.html
    #

    configs {
        # HDFS fencing should be set to true for HA configurations
        HDFS {
            dfs_ha_fencing_methods: "shell(true)"

            #
            # Optional configuration for Azure Data Lake Storage usage with
            # CDH. This requires that a valid service principal be created and
            # granted permission to access the ADLS account.
            # See: https://www.cloudera.com/documentation/enterprise/latest/topics/admin_adls_config.html
            #

            # core_site_safety_valve: """
            #     <property>
            #         <name>dfs.adls.oauth2.access.token.provider.type</name>
            #         <value>ClientCredential</value>
            #     </property>
            #     <property>
            #         <name>dfs.adls.oauth2.client.id</name>
            #         <value>client_id_REPLACE_ME</value>
            #     </property>
            #     <property>
            #         <name>dfs.adls.oauth2.credential</name>
            #         <value>client_secret_REPLACE_ME</value>
            #     </property>
            #     <property>
            #         <name>dfs.adls.oauth2.refresh.url</name>
            #         <value>refresh_url_REPLACE_ME</value>
            #     </property>
            # """
        }

        HIVE {
            audit_event_log_dir: /data0/log/hive/audit
            lineage_event_log_dir: /data0/log/hive/lineage
        }

        HBASE {
            audit_event_log_dir: /data0/log/hbase/audit
        }

        # OOZIE requires a load balancer specifically for high availability.
        # Director does not create or manage the load balancer.
        #
        # The load balancer must be configured with the IPs of the oozie servers
        # after the cluster completes bootstrapping.
        OOZIE {
          oozie_load_balancer: "example.com"
          oozie_load_balancer_http_port: 5002
          #oozie_load_balancer_https_port: 5000
        }
    }

    #
    # Database configuration for Highly Available Cluster Services
    #
    # As mentioned in the cloudera-manager section, the three mutually exclusive options for database
    # usage are (1) No configuration which uses databases in the Cloudera Manager embedded PostgreSQL
    # database server; (2) Use existing external databases; or (3) Create databases on an existing
    # external database server.
    #
    # High availibility configuration requires external databases to be defined for the
    # Hive Metastore, Hue, and Oozie services. These databases may be configured using either option
    # 2 or 3.
    #

    #
    # (Option 2) Configuration for existing external databases for services
    #

    # databases {
    #     HIVE {
    #         type: postgresql
    #         host: db.example.com
    #         port: 123
    #         user: hive
    #         password: pass
    #         name: hive_db
    #     }
    #     HUE {
    #         type: postgresql
    #         host: db.example.com
    #         port: 123
    #         user: hue
    #         password: pass
    #         name: hue_db
    #     }
    #     OOZIE {
    #         type: postgresql
    #         host: db.example.com
    #         port: 123
    #         user: oozie
    #         password: pass
    #         name: oozie_db
    #     }
    # }

    #
    # (Option 3) Configuration for creating external databases on the fly for services
    #

    databaseTemplates: {
        HIVE {
            name: hivet
            databaseServerName: existingmysql1
            databaseNamePrefix: hive
            usernamePrefix: hiveu
        }

        HUE {
            name: huet
            databaseServerName: existingmysql1
            databaseNamePrefix: hue
            usernamePrefix: hueu
        }

        OOZIE {
            name: ooziet
            databaseServerName: existingmysql1
            databaseNamePrefix: oozie
            usernamePrefix: oozieu
        }
    }

    #
    # Instance group configurations
    #
    #
    # This reference configuration follows the Cloudera Azure Reference Architecture.
    #

    masters-1 {
        count: 2

        instance: ${instances.master-1} {
            tags {
                group: masters-1
            }
        }

        roles {
            # ZooKeeper uses majority quorum for r/w, configure odd number of servers.
            ZOOKEEPER: [SERVER]
            HDFS: [NAMENODE, FAILOVERCONTROLLER, JOURNALNODE]
            YARN: [RESOURCEMANAGER]
            HBASE: [MASTER]
        }

        configs {

            # NameNode nameservice, autofailover, and quorum journal name must be configured for high availability
            HDFS {
                NAMENODE {
                    dfs_federation_namenode_nameservice: hanameservice
                    autofailover_enabled: true
                    dfs_namenode_quorum_journal_name: hanameservice

                    namenode_log_dir: /data0/log/hadoop-hdfs
                    dfs_name_dir_list: /data1/dfs/nn
                }
                FAILOVERCONTROLLER {
                    failover_controller_log_dir: /data0/log/hadoop-hdfs
                }
                JOURNALNODE {
                  journalnode_log_dir: /data0/log/hadoop-hdfs
                  dfs_journalnode_edits_dir: /data1/hdfs
                }
            }

            ZOOKEEPER {
                SERVER {
                    zk_server_log_dir: /data0/log/zookeeper
                    dataDir: /data2/zookeeper
                    dataLogDir: /data2/zookeeper
                }
            }

            YARN {
                RESOURCEMANAGER {
                    resource_manager_log_dir: /data0/log/hadoop-yarn
                }
            }

            HBASE {
                MASTER {
                    hbase_master_log_dir: /data0/log/hbase
                }
            }

        }
    }

    masters-2 {
        count: 1

        instance: ${instances.master-2} {
            tags {
                group: masters-2
            }
        }

        # HIVESERVER2 roles need a SPARK role (such as gateway) on the same
        # instance to pick up Spark configurations
        # Likewise, SPARK_ON_YARN roles need a HIVE gateway to read Hive tables
        roles {
            # ZooKeeper uses majority quorum for r/w, configure odd number of servers.
            ZOOKEEPER: [SERVER]
            HDFS: [JOURNALNODE, HTTPFS]
            HIVE: [HIVESERVER2, HIVEMETASTORE, WEBHCAT, GATEWAY]
            YARN: [JOBHISTORY]
            HUE: [HUE_SERVER]
            OOZIE: [OOZIE_SERVER]
            IMPALA: [CATALOGSERVER, STATESTORE]
            SPARK_ON_YARN: [SPARK_YARN_HISTORY_SERVER]
            HBASE: [HBASETHRIFTSERVER] # HBASETHRIFTSERVER role needed for HUE
        }

        configs {

            HDFS {
                JOURNALNODE {
                    journalnode_log_dir: /data0/log/hadoop-hdfs
                    dfs_journalnode_edits_dir: /data1/hdfs
                }
                HTTPFS {
                    httpfs_log_dir: /data0/log/hadoop-httpfs
                }
            }

            OOZIE {
                # Oozie plugins must be configured for high availability
                OOZIE_SERVER {
                    oozie_plugins_list: "org.apache.oozie.service.ZKLocksService,org.apache.oozie.service.ZKXLogStreamingService,org.apache.oozie.service.ZKJobsConcurrencyService,org.apache.oozie.service.ZKUUIDService"
                    oozie_log_dir: /data0/log/oozie
                }
            }

            ZOOKEEPER {
                SERVER {
                    zk_server_log_dir: /data0/log/zookeeper
                    dataDir: /data2/zookeeper
                    dataLogDir: /data2/zookeeper
                }
            }

            HIVE {
                HIVEMETASTORE {
                    hive_log_dir: /data0/log/hive
                }
                HIVESERVER2 {
                    hive_log_dir: /data0/log/hive
                }
                WEBHCAT {
                    hcatalog_log_dir: /data0/log/hcatalog
                }
            }

            YARN {
                JOBHISTORY {
                    mr2_jobhistory_log_dir: /data0/log/hadoop-mapreduce
                }
            }

            HUE {
                HUE_SERVER {
                    hue_server_log_dir: /data0/log/hue
                }
                KT_RENEWER {
                    kt_renewer_log_dir: /data0/log/hue
                }
            }

            IMPALA {
                CATALOGSERVER {
                    log_dir: /data0/log/catalogd
                }
                STATESTORE {
                    log_dir: /data0/log/statestore
                }
            }

            SPARK_ON_YARN {
                SPARK_YARN_HISTORY_SERVER {
                    log_dir: /data0/log/spark
                }
            }

            HBASE {
                HBASETHRIFTSERVER {
                    hbase_thriftserver_log_dir: /data0/log/hbase
                }
                #HBASERESTSERVER {
                #    hbase_restserver_log_dir: /data0/log/hbase
                #}
            }

        }
    }

    workers {

        #
        # The desired number of instances for this instance group. Cloudera Altus Director attempts
        # to launch this many instances, but will not fail bootstrap as long as the minimum number
        # of instances, specified with minCount below, succeed.
        #

        count: 5

        #
        # Minimum number of instances required for this instance group.
        # Altus Director will fail bootstrap of a cluster if minCount number of instances are not
        # available in this cloud environment.
        # If minCount is not specified then minCount is set to count.
        #

        minCount: 3

        instance: ${instances.worker} {
            tags {
                group: worker
            }
        }

        roles {
            HDFS: [DATANODE]
            YARN: [NODEMANAGER]
            HBASE: [REGIONSERVER]
            IMPALA: [IMPALAD]
        }

        configs {

            HDFS {
                DATANODE {
                    datanode_log_dir: /data0/log/hadoop-hdfs
                    dfs_data_dir_list: "/data1/dfs/dn,/data2/dfs/dn,/data3/dfs/dn,/data4/dfs/dn,/data5/dfs/dn,/data6/dfs/dn,/data7/dfs/dn,/data8/dfs/dn,/data9/dfs/dn,/data10/dfs/dn"
                }
            }

            YARN {
                NODEMANAGER {
                    node_manager_log_dir: /data0/log/hadoop-yarn
                    yarn_nodemanager_log_dirs: "/data1/log/hadoop-yarn/container,/data2/log/hadoop-yarn/container,/data3/log/hadoop-yarn/container,/data4/log/hadoop-yarn/container,/data5/log/hadoop-yarn/container,/data6/log/hadoop-yarn/container,/data7/log/hadoop-yarn/container,/data8/log/hadoop-yarn/container,/data9/log/hadoop-yarn/container,/data10/log/hadoop-yarn/container"
                    yarn_nodemanager_local_dirs: "/data1/yarn,/data2/yarn,/data3/yarn,/data4/yarn,/data5/yarn,/data6/yarn,/data7/yarn,/data8/yarn,/data9/yarn,/data10/yarn"
                }
            }

            HBASE {
                REGIONSERVER {
                    hbase_regionserver_log_dir: /data0/log/hbase
                }
            }

            IMPALA {
                IMPALAD {
                    log_dir: /data0/log/impalad
                    lineage_event_log_dir: /data0/log/impalad/lineage
                    audit_event_log_dir: /data0/log/impalad/audit
                    scratch_dirs: "/data1/impala/impalad,/data2/impala/impalad,/data3/impala/impalad,/data4/impala/impalad,/data5/impala/impalad,/data6/impala/impalad,/data7/impala/impalad,/data8/impala/impalad,/data9/impala/impalad,/data10/impala/impalad"
                }
            }

        }
    }
}
